{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import urllib\n",
    "import cv2\n",
    "import time\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add parent folder to path as parent folder contains required file to run this modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add libs form parent folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the variables\n",
    "In this example, I have used Android IP camera to get the live feed. So I need to configure the OpenCV to feed to live video to model directly from my phone (IP:192.168.1.4 )\n",
    "\n",
    "By default an \"SSD with Mobilenet\" model is used here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.__version__ < '1.4.0':\n",
    "    raise ImportError(\n",
    "        'Please upgrade your tensorflow installation to v1.4.* or later!')\n",
    "    \n",
    "    \n",
    "url = 'http://192.168.1.4:8080/video'\n",
    "\n",
    "\n",
    "# What model to download.\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 90  #number of class present in the training.\n",
    "\n",
    "outFile = \"/home/guru/test.mp4\"\n",
    "# fourcc stands for four character code\n",
    "codec = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "framerate = 30\n",
    "resolution = (640, 480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opener = urllib.request.URLopener()\n",
    "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "tar_file = tarfile.open(MODEL_FILE)\n",
    "for file in tar_file.getmembers():\n",
    "  file_name = os.path.basename(file.name)\n",
    "  if 'frozen_inference_graph.pb' in file_name:\n",
    "    tar_file.extract(file, os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load label map\n",
    "Label map is used to identify the correct value from the key produced by the convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file = cv2.VideoWriter(outFile, codec, framerate, resolution)\n",
    "\n",
    "# if you are getting CUDA MEMORY OVERFLOW error( for tensorflow-gpu version), add this as config in session.\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "bytes = b''\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(config=config, graph=detection_graph) as sess:\n",
    "\n",
    "        stream = urllib.request.urlopen(url)\n",
    "\n",
    "        while (True):\n",
    "            bytes += stream.read(1024)\n",
    "            a = bytes.find(b'\\xff\\xd8')\n",
    "            b = bytes.find(b'\\xff\\xd9')\n",
    "            if a != -1 and b != -1:\n",
    "                jpg = bytes[a:b + 2]\n",
    "                bytes = bytes[b + 2:]\n",
    "                image_np = cv2.imdecode(np.fromstring(\n",
    "                    jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "\n",
    "                #input and output Tensors for graph\n",
    "                image_tensor = detection_graph.get_tensor_by_name(\n",
    "                    'image_tensor:0')\n",
    "                \n",
    "                detection_boxes = detection_graph.get_tensor_by_name(\n",
    "                    'detection_boxes:0')\n",
    "                \n",
    "                detection_scores = detection_graph.get_tensor_by_name(\n",
    "                    'detection_scores:0')\n",
    "                \n",
    "                detection_classes = detection_graph.get_tensor_by_name(\n",
    "                    'detection_classes:0')\n",
    "                \n",
    "                num_detections = detection_graph.get_tensor_by_name(\n",
    "                    'num_detections:0')\n",
    "\n",
    "                # Expand array to shape: [1, None, None, 3]\n",
    "                image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "                \n",
    "                # Start the detection\n",
    "                (boxes, scores, classes, num) = sess.run(\n",
    "                    [detection_boxes, detection_scores,\n",
    "                        detection_classes, num_detections],\n",
    "                    feed_dict={image_tensor: image_np_expanded})\n",
    "                # Disply the detected object\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                    image_np,\n",
    "                    np.squeeze(boxes),\n",
    "                    np.squeeze(classes).astype(np.int32),\n",
    "                    np.squeeze(scores),\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=8)\n",
    "\n",
    "                video_file.write(image_np)\n",
    "                cv2.imshow('live_detection', image_np)\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    cv2.destroyAllWindows()\n",
    "                    cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
